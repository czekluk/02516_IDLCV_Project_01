[
    {
        "model_name": "DummyNet",
        "model": "DummyNet(\n  (convolutional): Sequential(\n    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Dropout2d(p=0.2, inplace=False)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout2d(p=0.2, inplace=False)\n  )\n  (fully_connected): Sequential(\n    (0): Linear(in_features=65536, out_features=500, bias=True)\n    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=500, out_features=2, bias=True)\n  )\n)",
        "train_acc": [
            0.6326331216414265
        ],
        "test_acc": [
            0.6895810955961332
        ],
        "train_loss": [
            0.7225799188017845
        ],
        "test_loss": [
            0.6134877115488052
        ],
        "epochs": 1,
        "optimizer_config": {
            "optimizer": "<class 'torch.optim.sgd.SGD'>",
            "params": {
                "lr": 0.01,
                "momentum": 0.9
            }
        }
    },
    {
        "model_name": "DummyNet",
        "model": "DummyNet(\n  (convolutional): Sequential(\n    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Dropout2d(p=0.2, inplace=False)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout2d(p=0.2, inplace=False)\n  )\n  (fully_connected): Sequential(\n    (0): Linear(in_features=65536, out_features=500, bias=True)\n    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=500, out_features=2, bias=True)\n  )\n)",
        "train_acc": [
            0.6658524670249145
        ],
        "test_acc": [
            0.6509129967776585
        ],
        "train_loss": [
            0.6958995386958122
        ],
        "test_loss": [
            0.622986693183581
        ],
        "epochs": 1,
        "optimizer_config": {
            "optimizer": "<class 'torch.optim.adam.Adam'>",
            "params": {
                "lr": 0.001
            }
        }
    },
    {
        "model_name": "DummyNet",
        "model": "DummyNet(\n  (convolutional): Sequential(\n    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Dropout2d(p=0.2, inplace=False)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout2d(p=0.2, inplace=False)\n  )\n  (fully_connected): Sequential(\n    (0): Linear(in_features=65536, out_features=500, bias=True)\n    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=500, out_features=2, bias=True)\n  )\n)",
        "train_acc": [
            0.6756228627259404
        ],
        "test_acc": [
            0.6283566058002148
        ],
        "train_loss": [
            0.6429558312520385
        ],
        "test_loss": [
            0.6673375566800436
        ],
        "epochs": 1,
        "optimizer_config": {
            "optimizer": "<class 'torch.optim.sgd.SGD'>",
            "params": {
                "lr": 0.01,
                "momentum": 0.9
            }
        }
    },
    {
        "model_name": "DummyNet",
        "model": "DummyNet(\n  (convolutional): Sequential(\n    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Dropout2d(p=0.2, inplace=False)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout2d(p=0.2, inplace=False)\n  )\n  (fully_connected): Sequential(\n    (0): Linear(in_features=65536, out_features=500, bias=True)\n    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=500, out_features=2, bias=True)\n  )\n)",
        "train_acc": [
            0.5984367366878358
        ],
        "test_acc": [
            0.5891514500537057
        ],
        "train_loss": [
            0.8060271311551332
        ],
        "test_loss": [
            0.6584462443987529
        ],
        "epochs": 1,
        "optimizer_config": {
            "optimizer": "<class 'torch.optim.adam.Adam'>",
            "params": {
                "lr": 0.001
            }
        }
    },
    {
        "model_name": "DummyNet",
        "model": "DummyNet(\n  (convolutional): Sequential(\n    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Dropout2d(p=0.2, inplace=False)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout2d(p=0.2, inplace=False)\n  )\n  (fully_connected): Sequential(\n    (0): Linear(in_features=65536, out_features=500, bias=True)\n    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=500, out_features=2, bias=True)\n  )\n)",
        "train_acc": [
            0.6795310210063508
        ],
        "test_acc": [
            0.5778732545649838
        ],
        "train_loss": [
            0.6679591946303844
        ],
        "test_loss": [
            0.6621892333030701
        ],
        "epochs": 1,
        "optimizer_config": {
            "optimizer": "<class 'torch.optim.adam.Adam'>",
            "params": {
                "lr": 0.001
            }
        }
    },
    {
        "model_name": "DummyNet",
        "model": "DummyNet(\n  (convolutional): Sequential(\n    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Dropout2d(p=0.2, inplace=False)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU()\n    (11): Dropout2d(p=0.2, inplace=False)\n  )\n  (fully_connected): Sequential(\n    (0): Linear(in_features=65536, out_features=500, bias=True)\n    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=500, out_features=2, bias=True)\n  )\n)",
        "train_acc": [
            0.6604787493893503
        ],
        "test_acc": [
            0.5042964554242749
        ],
        "train_loss": [
            0.6998098939657211
        ],
        "test_loss": [
            0.739972785115242
        ],
        "epochs": 1,
        "optimizer_config": {
            "optimizer": "<class 'torch.optim.adam.Adam'>",
            "params": {
                "lr": 0.001
            }
        }
    }
]